{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bcb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765a31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned resume data\n",
    "resumes = pd.read_csv(\"combined_resume_cleaned.csv\")\n",
    "\n",
    "# BERT embeddings\n",
    "resume_embeddings = np.load(\"resume_embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33052036",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = resumes['career_label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0c5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(y_encoded))\n",
    "\n",
    "X_train_idx, X_test_idx, y_train, y_test = train_test_split(\n",
    "    indices,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef247e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['career_label', 'skills', 'experience_years', 'education_level']\n"
     ]
    }
   ],
   "source": [
    "print(resumes.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b44b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_text = (\n",
    "    'skills ' + resumes['skills'].astype(str) +\n",
    "    ' experience ' + resumes['experience_years'].astype(str) + ' years' +\n",
    "    ' education ' + resumes['education_level'].astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e80a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(tfidf_text)\n",
    "\n",
    "X_train_tfidf = X_tfidf[X_train_idx]\n",
    "X_test_tfidf = X_tfidf[X_test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd0c71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd740295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline 1: Logistic Regression + TF-IDF ===\n",
      "Accuracy: 0.5938061041292639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       1.00      0.96      0.98        45\n",
      "           3       0.00      0.00      0.00        47\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.78      0.56      0.65        50\n",
      "           8       0.61      0.49      0.54        51\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.54      0.49      0.52        51\n",
      "          11       0.45      0.35      0.40        48\n",
      "          12       0.17      0.29      0.22        48\n",
      "          13       0.34      0.26      0.29        47\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.80      0.83      0.82       103\n",
      "          16       0.50      0.44      0.47        45\n",
      "          17       0.73      0.73      0.73       151\n",
      "          18       1.00      0.38      0.55         8\n",
      "          19       0.86      0.95      0.90       165\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.53      0.69      0.60        49\n",
      "          22       0.63      0.70      0.67        64\n",
      "          23       0.40      0.12      0.18        52\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.68      0.48      0.57        54\n",
      "          26       1.00      0.50      0.67         6\n",
      "          27       0.45      0.62      0.53         8\n",
      "          28       0.60      0.71      0.65        49\n",
      "          29       0.40      0.60      0.48        48\n",
      "          30       1.00      0.33      0.50         3\n",
      "          31       0.00      0.00      0.00         8\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.00      0.00      0.00         9\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.48      0.75      0.58        52\n",
      "          36       0.36      0.31      0.33        45\n",
      "          37       0.47      0.53      0.50        17\n",
      "          38       0.79      0.72      0.75        53\n",
      "          39       0.22      0.25      0.24         8\n",
      "          40       0.45      0.20      0.28        49\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         5\n",
      "          43       0.43      0.38      0.40         8\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.62      0.87      0.72       152\n",
      "          46       0.00      0.00      0.00        11\n",
      "          47       0.71      0.50      0.59        10\n",
      "          48       0.52      0.52      0.52        50\n",
      "          49       0.90      0.88      0.89        51\n",
      "          50       0.00      0.00      0.00         8\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.33      0.08      0.12        13\n",
      "          53       0.60      0.73      0.66       158\n",
      "          54       0.38      0.27      0.31        45\n",
      "          55       0.62      0.57      0.59        14\n",
      "          56       0.67      0.62      0.64        45\n",
      "          57       0.54      0.88      0.67       101\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.23      0.47      0.30        45\n",
      "          60       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.59      2228\n",
      "   macro avg       0.39      0.35      0.35      2228\n",
      "weighted avg       0.56      0.59      0.57      2228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline 1: Logistic Regression + TF-IDF ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec48c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f183ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline 2: Random Forest + TF-IDF ===\n",
      "Accuracy: 0.6032315978456014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.93      0.96      0.95        45\n",
      "           3       0.00      0.00      0.00        47\n",
      "           4       0.50      0.14      0.22         7\n",
      "           5       0.40      0.40      0.40         5\n",
      "           6       1.00      0.62      0.77         8\n",
      "           7       0.67      0.58      0.62        50\n",
      "           8       0.55      0.61      0.58        51\n",
      "           9       1.00      0.40      0.57         5\n",
      "          10       0.54      0.53      0.53        51\n",
      "          11       0.42      0.40      0.41        48\n",
      "          12       0.20      0.35      0.26        48\n",
      "          13       0.36      0.19      0.25        47\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.78      0.83      0.81       103\n",
      "          16       0.46      0.49      0.47        45\n",
      "          17       0.72      0.68      0.70       151\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       0.87      0.91      0.89       165\n",
      "          20       1.00      0.29      0.44         7\n",
      "          21       0.48      0.71      0.57        49\n",
      "          22       0.68      0.70      0.69        64\n",
      "          23       0.50      0.13      0.21        52\n",
      "          24       0.44      0.67      0.53         6\n",
      "          25       0.66      0.46      0.54        54\n",
      "          26       0.50      0.50      0.50         6\n",
      "          27       0.57      1.00      0.73         8\n",
      "          28       0.62      0.73      0.67        49\n",
      "          29       0.42      0.60      0.50        48\n",
      "          30       0.67      0.67      0.67         3\n",
      "          31       0.67      0.50      0.57         8\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       1.00      0.22      0.36         9\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.48      0.75      0.59        52\n",
      "          36       0.38      0.31      0.34        45\n",
      "          37       0.67      0.47      0.55        17\n",
      "          38       0.74      0.74      0.74        53\n",
      "          39       0.67      0.25      0.36         8\n",
      "          40       0.45      0.20      0.28        49\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         5\n",
      "          43       0.73      1.00      0.84         8\n",
      "          44       0.29      0.33      0.31         6\n",
      "          45       0.78      0.78      0.78       152\n",
      "          46       0.38      0.45      0.42        11\n",
      "          47       0.83      1.00      0.91        10\n",
      "          48       0.44      0.48      0.46        50\n",
      "          49       0.85      0.92      0.89        51\n",
      "          50       0.50      0.25      0.33         8\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.00      0.00      0.00        13\n",
      "          53       0.61      0.66      0.63       158\n",
      "          54       0.43      0.22      0.29        45\n",
      "          55       0.47      0.57      0.52        14\n",
      "          56       0.79      0.58      0.67        45\n",
      "          57       0.54      0.89      0.67       101\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.22      0.44      0.30        45\n",
      "          60       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.60      2228\n",
      "   macro avg       0.51      0.46      0.45      2228\n",
      "weighted avg       0.60      0.60      0.59      2228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline 2: Random Forest + TF-IDF ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00ed323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert = resume_embeddings[X_train_idx]\n",
    "X_test_bert = resume_embeddings[X_test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd66e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(np.unique(y_encoded)),\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_bert, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test_bert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ece6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Proposed Hybrid Model: BERT + XGBoost ===\n",
      "Accuracy: 0.6449730700179533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.36         4\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       1.00      0.96      0.98        45\n",
      "           3       0.23      0.15      0.18        47\n",
      "           4       0.50      0.14      0.22         7\n",
      "           5       0.33      0.20      0.25         5\n",
      "           6       0.35      1.00      0.52         8\n",
      "           7       0.66      0.66      0.66        50\n",
      "           8       0.58      0.67      0.62        51\n",
      "           9       1.00      0.40      0.57         5\n",
      "          10       0.76      0.63      0.69        51\n",
      "          11       0.53      0.42      0.47        48\n",
      "          12       0.23      0.29      0.26        48\n",
      "          13       0.45      0.36      0.40        47\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.85      0.80      0.82       103\n",
      "          16       0.73      0.80      0.77        45\n",
      "          17       0.69      0.75      0.72       151\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       0.88      0.91      0.89       165\n",
      "          20       0.67      0.57      0.62         7\n",
      "          21       0.72      0.69      0.71        49\n",
      "          22       0.76      0.92      0.83        64\n",
      "          23       0.41      0.23      0.30        52\n",
      "          24       1.00      0.50      0.67         6\n",
      "          25       0.68      0.52      0.59        54\n",
      "          26       0.67      1.00      0.80         6\n",
      "          27       0.57      1.00      0.73         8\n",
      "          28       0.72      0.67      0.69        49\n",
      "          29       0.55      0.50      0.52        48\n",
      "          30       0.67      0.67      0.67         3\n",
      "          31       1.00      0.50      0.67         8\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       1.00      0.22      0.36         9\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.50      0.71      0.59        52\n",
      "          36       0.32      0.27      0.29        45\n",
      "          37       0.74      0.82      0.78        17\n",
      "          38       0.72      0.72      0.72        53\n",
      "          39       1.00      0.25      0.40         8\n",
      "          40       0.38      0.22      0.28        49\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.33      0.40      0.36         5\n",
      "          43       1.00      1.00      1.00         8\n",
      "          44       0.57      0.67      0.62         6\n",
      "          45       0.77      0.72      0.74       152\n",
      "          46       0.55      0.55      0.55        11\n",
      "          47       0.91      1.00      0.95        10\n",
      "          48       0.58      0.52      0.55        50\n",
      "          49       0.85      0.90      0.88        51\n",
      "          50       0.60      0.38      0.46         8\n",
      "          51       0.67      0.40      0.50         5\n",
      "          52       0.40      0.15      0.22        13\n",
      "          53       0.72      0.68      0.70       158\n",
      "          54       0.44      0.42      0.43        45\n",
      "          55       0.40      0.71      0.51        14\n",
      "          56       0.76      0.64      0.70        45\n",
      "          57       0.57      0.87      0.69       101\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.29      0.53      0.38        45\n",
      "          60       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.64      2228\n",
      "   macro avg       0.58      0.54      0.53      2228\n",
      "weighted avg       0.65      0.64      0.64      2228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Proposed Hybrid Model: BERT + XGBoost ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8866f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression + TF-IDF</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest + TF-IDF</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proposed Hybrid (BERT + XGBoost)</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Precision  Recall  F1-Score\n",
       "0      Logistic Regression + TF-IDF     0.594       0.56    0.59      0.57\n",
       "1            Random Forest + TF-IDF     0.603       0.60    0.60      0.59\n",
       "2  Proposed Hybrid (BERT + XGBoost)     0.645       0.65    0.64      0.64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "career_results_df = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression + TF-IDF\",\n",
    "        \"Random Forest + TF-IDF\",\n",
    "        \"Proposed Hybrid (BERT + XGBoost)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        0.594,   # from your output\n",
    "        0.603,   # from your output\n",
    "        0.645    # from your output\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        0.56,\n",
    "        0.60,\n",
    "        0.65\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        0.59,\n",
    "        0.60,\n",
    "        0.64\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        0.57,\n",
    "        0.59,\n",
    "        0.64\n",
    "    ]\n",
    "})\n",
    "\n",
    "career_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06dcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_results_df.to_csv(\"career_prediction_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
